{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of electrical features (eFeatures) from experimental data\n",
    "\n",
    "____\n",
    "\n",
    "## Overview (from last week)\n",
    "\n",
    "____\n",
    "\n",
    "In this tutorial we will see how to extract electrical features (eFeatures), such as spike amplitude, firing frequency, etc... from experimental traces. The eFeatures describe the electrical behavior our neuron model should reproduce.\n",
    "\n",
    "The steps we will follow are:\n",
    "\n",
    "* Select and visualize the data.\n",
    "\n",
    "* Electrophysiological features will be extracted from the voltage traces, thanks to the ** Electrophys Feature Extraction Library ** [eFEL](https://github.com/BlueBrain/eFEL).\n",
    "\n",
    "* We will use experimental current traces to create protocols that we will use to simulate our neuron model.\n",
    "\n",
    "* In future weeks we will use the **Blue Brain Python Optimisation Library** [BluePyOpt](https://github.com/BlueBrain/BluePyOpt) to create a model template for the [NEURON simulator](https://www.neuron.yale.edu/neuron/). There you'll see how the morphology you've chosen, the eFeatures and the stimuli will be combined in setting up the optimization of your neuron model.\n",
    "\n",
    "___\n",
    "### You will implement part of the code in order to perform the steps above (follow the **TODOs** in this notebook).\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # To avoid problems, install the pacakges you will need.\n",
    "! pip install --upgrade pip\n",
    "! pip install json2html\n",
    "# First execute this line to upgrade pip\n",
    "! pip install -q --upgrade \"hbp-service-client==1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESTART YOUR KERNEL NOW!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some useful Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import numpy, IPython\n",
    "import json, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import collections\n",
    "\n",
    "from json2html import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Electrophysiology data\n",
    "\n",
    "Go to the __MOODLE__ and download the folder called __Layer5TuftedPyramidal.tar__ files. Then, save these files in the __Storage__ of your collab. (Please, unzip the folder before saving it in the Storage). There are a lot of files, so is better to create a folder in the Storage and save the files in the folder. I called the folder __\"dataLayer5TuftedPyramidal\"__\n",
    "\n",
    "In this section we will process the electrophysiological data recorded with patch clamp (current clamp) experiments.\n",
    "\n",
    "We will store the data in a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the files from the Storage to your collab virtual machine\n",
    "# Save the file's names in a list\n",
    "# Be patient it could take some minutes...\n",
    "\n",
    "# These lines allow us to take and work with the desired files in the storage.\n",
    "clients = get_hbp_service_client()\n",
    "collab_path = get_collab_storage_path()\n",
    "data_dir = collab_path + '/dataLayer5TuftedPyramidal/'\n",
    "\n",
    "#print files_list\n",
    "project_uuid = clients.storage.api_client.get_entity_by_query(path=data_dir)['uuid']\n",
    "l = clients.storage.api_client.list_folder_content(project_uuid, page_size=300)\n",
    "\n",
    "filenames = []\n",
    "for e in l['results']:\n",
    "    filenames.append(e['name'])\n",
    "\n",
    "for filename in filenames:\n",
    "    print filename\n",
    "    path_to_file = '/tmp/downloaded_'+filename\n",
    "    file_from_path = data_dir+filename\n",
    "    clients.storage.download_file(str(data_dir+filename), str(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Traces description\n",
    "\n",
    "* All the recordings you see above represent different **stimuli** (e.g. \"APWaveform\", \"IDRest\", \"IV\"). \n",
    "* Each stimulus comprises different **sweeps** (e.g. \"APWaveform*46-51\"), of increasing/decreasing amplitudes.\n",
    "* Each stimulus is repeated multiple times (e.g. APWaveform 46-51, 1042-1047, 2042-2047, 3042-3047 ). In this example above we have four **repetitions** of each stimulus.\n",
    "\n",
    "Any individual recording has a trace number (e.g. \"_1046\"). Note that we have pairs of recordings with the same trace number (e.g. \"exp_APWaveform_ch7_51.dat\" and \"exp_APWaveform_ch6_51.dat\"). One of them contains the current stimulus (in this case \"*ch7*\") and the other the voltage response (in this case \"*ch6*\").\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** With the code below we select traces based on trace number and store them in Python dictionaries. Last week we chose three stimuli and three repetitions. You are free to choose less stimuli, if you think that the firing of your neuron can be well described with a smaller stimuli subset. However, you should choose more than one repetition, as we've seen that the same cell may respond a bit differently although the stimulus is the same.\n",
    "\n",
    "If you choose different stimuli, look carefully at the code below the \"TODO\", to have the appropriate number of entries and names in the \"steps_v_dict\" and \"stepv_i_dict\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO modify the line below to write the trace numbers of your choice in the list \"selected traces\"\n",
    "selected_traces = [...,...,...,...,...,...]\n",
    "\n",
    "# Store voltage data in a dictionary step_name : [list of repetitions]\n",
    "steps_v_dict = collections.OrderedDict({'LongStepNeg': [], 'ShortStepPos': [], 'LongStepPos': []})\n",
    "\n",
    "# Store current data in a dictionary step_name : [list of repetitions]\n",
    "steps_i_dict = collections.OrderedDict({'LongStepNeg': [], 'ShortStepPos': [], 'LongStepPos': []})\n",
    "\n",
    "for file_name in filenames:\n",
    "    # Get channel and trace number from the file_name\n",
    "    channel = int(file_name[:-4].split('_')[2][2:])\n",
    "    tracenum = int(file_name[:-4].split('_')[-1])\n",
    "    path_to_file = '/tmp/downloaded_'+file_name\n",
    "    \n",
    "    # Even channel numbers are voltage traces in this case\n",
    "    if channel % 2 == 0:\n",
    "        if \"APWaveform\" in file_name and tracenum in selected_traces:\n",
    "            steps_v_dict['ShortStepPos'].append(numpy.fromfile(path_to_file))\n",
    "        if \"IDRest\" in file_name and tracenum in selected_traces:\n",
    "            steps_v_dict['LongStepPos'].append(numpy.fromfile(path_to_file))\n",
    "        if \"IV\" in file_name and tracenum in selected_traces:\n",
    "            steps_v_dict['LongStepNeg'].append(numpy.fromfile(path_to_file))\n",
    "            \n",
    "    # Odd channel numbers are voltage traces in this case        \n",
    "    elif channel % 2 == 1:\n",
    "        if \"APWaveform\" in file_name and tracenum in selected_traces:\n",
    "            steps_i_dict['ShortStepPos'].append(numpy.fromfile(path_to_file))\n",
    "        if \"IDRest\" in file_name and tracenum in selected_traces:\n",
    "            steps_i_dict['LongStepPos'].append(numpy.fromfile(path_to_file))\n",
    "        if \"IV\" in file_name and tracenum in selected_traces:\n",
    "            steps_i_dict['LongStepNeg'].append(numpy.fromfile(path_to_file))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** We can now plot these traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: if you run this cell, without any modification, you should see the traces. \n",
    "# Each subpart of the figure shows the repetitions of one stimulus\n",
    "\n",
    "# Initialize a figure\n",
    "fig1, axes = plt.subplots(len(steps_v_dict), sharey = True, figsize=(20,15))\n",
    "\n",
    "# Plot the voltage traces\n",
    "for idx, step_name in enumerate(steps_v_dict.keys()):\n",
    "    for rep, trace in enumerate(steps_v_dict[step_name]):\n",
    "        data = trace.reshape(len(trace)/2,2)\n",
    "        axes[idx].plot(data[:,0],data[:,1], label = 'Rep. ' + str(rep+1))\n",
    "        axes[idx].set_ylabel('Voltage (mV)')\n",
    "        axes[idx].legend(loc = 'best')\n",
    "        axes[idx].set_title(step_name)\n",
    "    axes[-1].set_xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Electrophysiological features\n",
    "To build a detailed neuron model, we need to quantify the electrical behavior we want to reproduce. The metrics we use are the eFeatures, that measure parameters describing for instance the shape of the action potential or the firing rate of a neuron.\n",
    "\n",
    "The eFeatures extracted from the data and later from the model will be used to compare the model's responses with the experimental data. The mean features values, along with the standard deviations will be stored in a .json file.\n",
    "\n",
    "**TODO** You will define the information on the stimulus start and end times, along with the eFeatures you want to extract. Look at [here](http://bluebrain.github.io/eFEL/eFeatures.html) to have an idea on the eFeatures that you can extract or use the function \"efel.getFeatureNames()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "import efel\n",
    "\n",
    "# TODO: Look at the plots above to find the stimulus start and end time for each stimulus (in ms),\n",
    "# Replace \"0\" and \"10000' with stimulus start and end times\n",
    "steps_info = {'LongStepNeg': [0, 10000], 'ShortStepPos': [0, 10000], 'LongStepPos': [0, 10000]}\n",
    "\n",
    "# TODO: write here the feature names of your choice, for each stimulus you've chosen\n",
    "LongStepNeg_feat = ['voltage_base', '...']\n",
    "LongStepPos_feat = ['AP_amplitude', '...']\n",
    "ShortStepPos_feat = ['AHP_depth_abs' '...']\n",
    "\n",
    "# Prepare the traces for eFEL\n",
    "def get_features(data):\n",
    "    # All the traces converted in eFEL format\n",
    "    efel_traces = {'LongStepNeg': [], 'ShortStepPos': [], 'LongStepPos': []}\n",
    "    for step_name, step_traces in data.items():\n",
    "        for rep in step_traces:            \n",
    "            data = rep.reshape(len(rep)/2,2)\n",
    "            # A single eFEL trace \n",
    "            trace = {}\n",
    "            trace['T'] = data[:,0]\n",
    "            trace['V'] = data[:,1] \n",
    "            trace['stim_start'] = [steps_info[step_name][0]]\n",
    "            trace['stim_end'] = [steps_info[step_name][1]]\n",
    "            trace['name'] = step_name\n",
    "            \n",
    "            efel_traces[step_name].append(trace)\n",
    "    \n",
    "    features_values = collections.defaultdict(dict)       \n",
    "    \n",
    "    features_values['LongStepNeg'] = efel.getMeanFeatureValues(efel_traces['LongStepNeg'], LongStepNeg_feat)\n",
    "    \n",
    "    features_values['LongStepPos'] = efel.getMeanFeatureValues(efel_traces['LongStepPos'], LongStepPos_feat)\n",
    "    \n",
    "    features_values['ShortStepPos'] = efel.getMeanFeatureValues(efel_traces['ShortStepPos'], ShortStepPos_feat)    \n",
    "\n",
    "    return features_values\n",
    "\n",
    "#efel.getFeatureNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** We can now visualise the feature values we computed, each row in the table corresponds to a repetition of the same step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: run the code below to visualize the features extracted from each repetition, each stimulus. \n",
    "# Do these values make sense?\n",
    "\n",
    "efel_features = dict(get_features(steps_v_dict))\n",
    "IPython.display.HTML(json2html.convert(json=efel_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute features mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: run the code below to compute the mean and standard deviations from the repetitions of each stimulus\n",
    "\n",
    "features_dict = collections.OrderedDict()\n",
    "for step_name, reps in efel_features.items():\n",
    "    feature_values = collections.defaultdict(list)\n",
    "    for rep in reps: \n",
    "        for feature_name, value in rep.iteritems():\n",
    "            feature_values[feature_name].append(value)\n",
    "   \n",
    "    features_dict[step_name] = {\"soma\":{}}\n",
    "    for name, values in feature_values.items():\n",
    "        features_dict[step_name][\"soma\"][name] = [numpy.mean(values), numpy.std(values)]\n",
    "        \n",
    "IPython.display.HTML(json2html.convert(json=dict(features_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write the eFeatures in a .json file that we will use later in the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: run the code below to save the efeatures in a .json file. You can also open it with a text editor and compare\n",
    "# with the same file we obtained last week.\n",
    "with open('features.json', 'w') as fp:\n",
    "    json.dump(features_dict, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see if we had created the file in the working directory of the collab virtual machine.\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute the lines below\n",
    "# This will save the files in the storage\n",
    "clients = get_hbp_service_client()\n",
    "collab_path = get_collab_storage_path()\n",
    "clients.storage.upload_file('features.json', data_dir + '/features.json', 'application/JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__ Compute all the possible eFeatures for the different traces during the different protocols.\n",
    "Why is it possible to comute some of them and not others?\n",
    "\n",
    "Hint: You can create a table or a bitmap to explain the solution in your project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Write out the stimulation protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to process the current stimuli that were used to record the voltage responses seen above.\n",
    "\n",
    "We will estimate the stimuli amplitude from the trace and save them in a file \"protocols.json\". They will be used later on in the project to stimulate your neuron model.\n",
    "\n",
    "**TODO** Plot the current traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: run this cell to visualize the current stimuli. The graph should appear similar \n",
    "# to the one with the voltage responses (multiple repetitions grouped by stimulus name)\n",
    "\n",
    "# Plot the current traces\n",
    "# Initialize a figure\n",
    "fig1, axes = plt.subplots(len(steps_i_dict), sharey = True, figsize=(20,15))\n",
    "\n",
    "for idx, step_name in enumerate(steps_i_dict.keys()):\n",
    "    for rep, trace in enumerate(steps_i_dict[step_name]):\n",
    "        data = trace.reshape(len(trace)/2,2)\n",
    "        axes[idx].plot(data[:,0],data[:,1], label = 'Rep. ' + str(rep+1))\n",
    "        axes[idx].set_ylabel('Current (nA)')\n",
    "        axes[idx].legend(loc = 'best')\n",
    "        axes[idx].set_title(step_name)\n",
    "    axes[-1].set_xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** copy the \"steps_info\" dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protocols_dict = collections.OrderedDict()\n",
    "\n",
    "# TODO: Replace the line below to copy the \"steps_info\" dictionary. \n",
    "# We will use the stimuli start and end to write the current protocol to simulate the response in our neuron\n",
    "steps_info = {'LongStepNeg': [0, 10000], 'ShortStepPos': [0, 10000], 'LongStepPos': [0, 10000]}\n",
    "\n",
    "# Stimuli holding current and step current amplitudes in nA\n",
    "amps_info = collections.defaultdict(list)\n",
    "for step_name in steps_i_dict.keys():\n",
    "    \n",
    "    iholds = []\n",
    "    isteps = []\n",
    "    for trace in steps_i_dict[step_name]:\n",
    "        data = trace.reshape(len(trace)/2,2)\n",
    "        tot_duration = steps_info[step_name][1]+steps_info[step_name][0]\n",
    "   \n",
    "        dt = float(tot_duration)/len(data)\n",
    "        ihold = numpy.mean(data[:,1][0:int(steps_info[step_name][0]/dt)])\n",
    "\n",
    "        istep = numpy.mean(data[:,1][int(steps_info[step_name][0]/dt):int(steps_info[step_name][1]/dt)])-ihold\n",
    "        iholds.append(ihold)\n",
    "        isteps.append(istep)\n",
    "       \n",
    "    amps_info[step_name].append(round(numpy.mean(isteps), 4))\n",
    "    amps_info[step_name].append(round(numpy.mean(iholds), 4)) \n",
    "    \n",
    "#amps_info  = {'LongStepNeg': [-0.01, 0.05], 'ShortStepPos': [0.18,0.05],'LongStepPos': [0.15 ,0.05]}\n",
    "\n",
    "for step_name, reps in efel_features.items():   \n",
    "    protocols_dict[step_name] = {\"stimuli\":[]}\n",
    "    protocols_dict[step_name][\"stimuli\"].append({\"delay\":steps_info[step_name][0],\n",
    "                                               \"amp\":amps_info[step_name][0],\n",
    "                                               \"duration\":steps_info[step_name][1]-steps_info[step_name][0],\n",
    "                                               \"totduration\":steps_info[step_name][1]+steps_info[step_name][0]})\n",
    "    protocols_dict[step_name][\"stimuli\"].append({\"delay\":0,\n",
    "                                               \"amp\":amps_info[step_name][1],\n",
    "                                               \"duration\":steps_info[step_name][1]+steps_info[step_name][0],\n",
    "                                               \"totduration\":steps_info[step_name][1]+steps_info[step_name][0]})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: run the line below to visualize the protocols that we have computed. \n",
    "# For each stimulus you should have two lines, representing the step current parameters and the holding current parameters\n",
    "IPython.display.HTML(json2html.convert(json=dict(protocols_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: save the protocols in the \"protocols.json\" information\n",
    "# Save the protocols in a .json file\n",
    "with open('protocols.json', 'w') as fp:\n",
    "    json.dump(protocols_dict, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute the lines below\n",
    "# This will save the file in the storage\n",
    "clients = get_hbp_service_client()\n",
    "collab_path = get_collab_storage_path()\n",
    "clients.storage.upload_file('protocols.json', data_dir + '/protocols.json', 'application/JSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
